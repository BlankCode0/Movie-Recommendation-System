{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Imports\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Step 2: Download and extract MovieLens 100K\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "file_path = \"ml-100k.zip\"\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "# Step 3: Load 'u.data'\n",
        "col_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=col_names)\n",
        "\n",
        "# Map user/item IDs to zero-based continuous indices\n",
        "df[\"user_id\"] = df[\"user_id\"].astype(\"category\").cat.codes\n",
        "df[\"item_id\"] = df[\"item_id\"].astype(\"category\").cat.codes\n",
        "\n",
        "n_users = df[\"user_id\"].nunique()\n",
        "n_items = df[\"item_id\"].nunique()\n",
        "print(f\"Loaded MovieLens-100k: {len(df)} ratings, {n_users} users, {n_items} movies.\")\n",
        "\n",
        "# Step 4: Create PyTorch dataset & dataloader\n",
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.users = torch.tensor(df[\"user_id\"].values, dtype=torch.long)\n",
        "        self.items = torch.tensor(df[\"item_id\"].values, dtype=torch.long)\n",
        "        self.ratings = torch.tensor(df[\"rating\"].values, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.ratings)\n",
        "    def __getitem__(self, idx): return self.users[idx], self.items[idx], self.ratings[idx]\n",
        "\n",
        "train_data = RatingDataset(df)\n",
        "train_loader = DataLoader(train_data, batch_size=512, shuffle=True)\n",
        "\n",
        "# Step 5: Define Matrix Factorization model\n",
        "class MF(nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors=50):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
        "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
        "        self.fc = nn.Linear(n_factors, 1)\n",
        "    def forward(self, u, i):\n",
        "        x = self.user_emb(u) * self.item_emb(i)\n",
        "        return self.fc(x).squeeze()\n",
        "\n",
        "model = MF(n_users, n_items)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 6: Train model\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "    for u, i, r in train_loader:\n",
        "        pred = model(u, i)\n",
        "        loss = criterion(pred, r)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Step 7: Recommend for a given user\n",
        "def recommend(user_id, top_n=5):\n",
        "    user = torch.tensor([user_id] * n_items)\n",
        "    items = torch.arange(n_items)\n",
        "    with torch.no_grad():\n",
        "        preds = model(user, items).numpy()\n",
        "    top_items = preds.argsort()[-top_n:][::-1]\n",
        "    return top_items\n",
        "\n",
        "print(\"Recommendations for User 0:\", recommend(0, top_n=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhyhTk6uo974",
        "outputId": "8fa2117f-2a81-4c12-db94-ebb9016c3c42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded MovieLens-100k: 100000 ratings, 943 users, 1682 movies.\n",
            "Epoch 1, Loss: 8.7544\n",
            "Epoch 2, Loss: 2.2049\n",
            "Epoch 3, Loss: 1.0745\n",
            "Epoch 4, Loss: 0.9334\n",
            "Epoch 5, Loss: 0.8749\n",
            "Epoch 6, Loss: 0.8134\n",
            "Epoch 7, Loss: 0.7337\n",
            "Epoch 8, Loss: 0.6487\n",
            "Epoch 9, Loss: 0.5700\n",
            "Epoch 10, Loss: 0.5004\n",
            "Epoch 11, Loss: 0.4416\n",
            "Epoch 12, Loss: 0.3927\n",
            "Epoch 13, Loss: 0.3508\n",
            "Epoch 14, Loss: 0.3171\n",
            "Epoch 15, Loss: 0.2891\n",
            "Epoch 16, Loss: 0.2666\n",
            "Epoch 17, Loss: 0.2491\n",
            "Epoch 18, Loss: 0.2321\n",
            "Epoch 19, Loss: 0.2199\n",
            "Epoch 20, Loss: 0.2091\n",
            "Epoch 21, Loss: 0.1994\n",
            "Epoch 22, Loss: 0.1917\n",
            "Epoch 23, Loss: 0.1841\n",
            "Epoch 24, Loss: 0.1781\n",
            "Epoch 25, Loss: 0.1728\n",
            "Epoch 26, Loss: 0.1677\n",
            "Epoch 27, Loss: 0.1636\n",
            "Epoch 28, Loss: 0.1602\n",
            "Epoch 29, Loss: 0.1564\n",
            "Epoch 30, Loss: 0.1529\n",
            "Epoch 31, Loss: 0.1502\n",
            "Epoch 32, Loss: 0.1470\n",
            "Epoch 33, Loss: 0.1441\n",
            "Epoch 34, Loss: 0.1419\n",
            "Epoch 35, Loss: 0.1394\n",
            "Epoch 36, Loss: 0.1369\n",
            "Epoch 37, Loss: 0.1348\n",
            "Epoch 38, Loss: 0.1329\n",
            "Epoch 39, Loss: 0.1317\n",
            "Epoch 40, Loss: 0.1308\n",
            "Epoch 41, Loss: 0.1285\n",
            "Epoch 42, Loss: 0.1268\n",
            "Epoch 43, Loss: 0.1256\n",
            "Epoch 44, Loss: 0.1249\n",
            "Epoch 45, Loss: 0.1229\n",
            "Epoch 46, Loss: 0.1216\n",
            "Epoch 47, Loss: 0.1201\n",
            "Epoch 48, Loss: 0.1192\n",
            "Epoch 49, Loss: 0.1180\n",
            "Epoch 50, Loss: 0.1167\n",
            "Recommendations for User 0: [1064  749  548  571  651]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload movies with proper columns\n",
        "movie_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
        "              'unknown','Action','Adventure','Animation','Children','Comedy','Crime',\n",
        "              'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery',\n",
        "              'Romance','Sci-Fi','Thriller','War','Western']\n",
        "movies = pd.read_csv('ml-100k/u.item', sep='|', names=movie_cols, encoding='latin-1')\n",
        "\n",
        "# Re-code movie_id to match df's encoding\n",
        "movies[\"item_id\"] = movies[\"movie_id\"].astype(\"category\").cat.codes\n",
        "\n",
        "# Build lookup dictionary: internal item_id â†’ movie title\n",
        "id_to_title = dict(zip(movies[\"item_id\"], movies[\"title\"]))\n",
        "\n",
        "def recommend_with_titles(user_id, top_n=5):\n",
        "    user = torch.tensor([user_id] * n_items)\n",
        "    items = torch.arange(n_items)\n",
        "    with torch.no_grad():\n",
        "        preds = model(user, items).numpy()\n",
        "    top_items = preds.argsort()[-top_n:][::-1]   # best N items\n",
        "    titles = [id_to_title[i] for i in top_items] # convert to titles\n",
        "    return titles\n",
        "\n",
        "print(\"Top Recommendations for User 0:\")\n",
        "print(recommend_with_titles(0, top_n=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxZAyNoPo-W4",
        "outputId": "892c8cea-0448-4253-f100-3381dc621158"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Recommendations for User 0:\n",
            "['Koyaanisqatsi (1983)', 'Amistad (1997)', 'Rob Roy (1995)', 'Blown Away (1994)', 'Rosencrantz and Guildenstern Are Dead (1990)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_new_user_ratings(new_ratings, model, movies, top_n=5):\n",
        "    \"\"\"\n",
        "    new_ratings: list of (movie_title, rating) given by the new user\n",
        "    model: trained MF model\n",
        "    movies: movie metadata dataframe\n",
        "    top_n: number of recommendations to return\n",
        "    \"\"\"\n",
        "    # Map titles to item_ids\n",
        "    title_to_id = dict(zip(movies[\"title\"], movies[\"item_id\"]))\n",
        "\n",
        "    # Convert ratings into tensors\n",
        "    item_ids = []\n",
        "    ratings = []\n",
        "    for title, rating in new_ratings:\n",
        "        if title in title_to_id:\n",
        "            item_ids.append(title_to_id[title])\n",
        "            ratings.append(rating)\n",
        "        else:\n",
        "            print(f\"Movie '{title}' not found in dataset.\")\n",
        "\n",
        "    item_ids = torch.tensor(item_ids, dtype=torch.long)\n",
        "    ratings = torch.tensor(ratings, dtype=torch.float32)\n",
        "\n",
        "    # --- Step 1: Get embeddings of movies the new user rated ---\n",
        "    item_vecs = model.item_emb(item_ids)\n",
        "\n",
        "    # Weighted average of embeddings (by rating)\n",
        "    user_vec = (item_vecs * ratings.unsqueeze(1)).mean(dim=0, keepdim=True)\n",
        "\n",
        "    # --- Step 2: Predict for all movies ---\n",
        "    items = torch.arange(n_items)\n",
        "    preds = (user_vec * model.item_emb(items)).sum(dim=1)\n",
        "\n",
        "    # --- Step 3: Exclude movies the user already rated ---\n",
        "    preds[item_ids] = -999   # mask out rated movies\n",
        "\n",
        "    # --- Step 4: Top-N recommendations (safe way) ---\n",
        "    top_items = torch.topk(preds, top_n).indices.numpy()\n",
        "\n",
        "    # Map to movie titles\n",
        "    recs = movies[movies[\"item_id\"].isin(top_items)][[\"title\"]]\n",
        "    return recs\n",
        "\n",
        "# ðŸ”¹ Example usage\n",
        "new_user_ratings = [\n",
        "    (\"Braveheart (1995)\", 5),\n",
        "    (\"Toy Story (1995)\", 4),\n",
        "    (\"Star Wars (1977)\", 5)\n",
        "]\n",
        "\n",
        "print(\"Recommendations for New User:\")\n",
        "print(add_new_user_ratings(new_user_ratings, model, movies, top_n=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L0GP7g4pnen",
        "outputId": "77a1fc28-aed6-4bbf-cbc2-288a4944df6c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for New User:\n",
            "                                          title\n",
            "171             Empire Strikes Back, The (1980)\n",
            "173              Raiders of the Lost Ark (1981)\n",
            "180                   Return of the Jedi (1983)\n",
            "209   Indiana Jones and the Last Crusade (1989)\n",
            "1128                   Chungking Express (1994)\n"
          ]
        }
      ]
    }
  ]
}